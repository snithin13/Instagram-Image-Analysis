{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install instaloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\win_unicode_console\\__init__.py:31: RuntimeWarning: sys.stdin.encoding == 'cp1252', whereas sys.stdout.encoding == 'UTF-8', readline hook consumer may assume they are the same\n",
      "  readline_hook.enable(use_pyreadline=use_pyreadline)\n"
     ]
    }
   ],
   "source": [
    "import instaloader\n",
    "from instaloader import Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = 'natgeo'\n",
    "\n",
    "L = instaloader.Instaloader()\n",
    "posts = instaloader.Profile.from_username(L.context, USERNAME).get_posts()\n",
    "\n",
    "df = pd.DataFrame(columns=['post_link', 'comment_count','likes_count','caption','is_video','image_link'])\n",
    "counter = 0\n",
    "\n",
    "for post in posts:\n",
    "    counter+=1\n",
    "    shortcode = post.shortcode\n",
    "    post_link = 'https://instagram.com/p/'+shortcode+'/'\n",
    "    likes = post.likes\n",
    "    comments = post.comments\n",
    "    caption = post.caption\n",
    "    video = post.is_video\n",
    "    image_link = post.url\n",
    "\n",
    "\n",
    "    df = df.append({'post_link':post_link, 'comment_count':comments, 'likes_count':likes, 'caption':caption,'image_link':image_link,'is_video':video}, ignore_index=True)\n",
    "    if counter>=600:\n",
    "        break\n",
    "photo_df = df[df['is_video']==False] #selecting only the photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#photo_df.to_csv('natgeo_insta_photo_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post_link</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>caption</th>\n",
       "      <th>is_video</th>\n",
       "      <th>image_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://instagram.com/p/B44MXP-gNxy/</td>\n",
       "      <td>209</td>\n",
       "      <td>79912</td>\n",
       "      <td>Photo by Keith Ladzinski @ladzinski | With a l...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/93c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://instagram.com/p/B433BqzAGIf/</td>\n",
       "      <td>685</td>\n",
       "      <td>178480</td>\n",
       "      <td>Photo by Cristina Mittermeier @Mitty | Did you...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://instagram.com/p/B43ibepIaV0/</td>\n",
       "      <td>511</td>\n",
       "      <td>110287</td>\n",
       "      <td>Photo by @jodicobbphoto | Heartbreaking floods...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/ca0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://instagram.com/p/B43OGVdD9Rx/</td>\n",
       "      <td>525</td>\n",
       "      <td>253331</td>\n",
       "      <td>Photos by Stephen Alvarez @salvarezphoto | My ...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/d98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://instagram.com/p/B425rKvjVLJ/</td>\n",
       "      <td>826</td>\n",
       "      <td>141166</td>\n",
       "      <td>Photo by @dina_litovsky | These are portraits ...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/b7f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             post_link  comment_count  \\\n",
       "0           0  https://instagram.com/p/B44MXP-gNxy/            209   \n",
       "1           1  https://instagram.com/p/B433BqzAGIf/            685   \n",
       "2           2  https://instagram.com/p/B43ibepIaV0/            511   \n",
       "3           3  https://instagram.com/p/B43OGVdD9Rx/            525   \n",
       "4           4  https://instagram.com/p/B425rKvjVLJ/            826   \n",
       "\n",
       "   likes_count                                            caption  is_video  \\\n",
       "0        79912  Photo by Keith Ladzinski @ladzinski | With a l...     False   \n",
       "1       178480  Photo by Cristina Mittermeier @Mitty | Did you...     False   \n",
       "2       110287  Photo by @jodicobbphoto | Heartbreaking floods...     False   \n",
       "3       253331  Photos by Stephen Alvarez @salvarezphoto | My ...     False   \n",
       "4       141166  Photo by @dina_litovsky | These are portraits ...     False   \n",
       "\n",
       "                                          image_link  \n",
       "0  https://instagram.fftw1-1.fna.fbcdn.net/vp/93c...  \n",
       "1  https://instagram.fftw1-1.fna.fbcdn.net/vp/235...  \n",
       "2  https://instagram.fftw1-1.fna.fbcdn.net/vp/ca0...  \n",
       "3  https://instagram.fftw1-1.fna.fbcdn.net/vp/d98...  \n",
       "4  https://instagram.fftw1-1.fna.fbcdn.net/vp/b7f...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_df = pd.read_csv('natgeo_insta_photo_posts.csv')\n",
    "photo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A: Engagement Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df.loc[:,('comment_normal')] = photo_df['comment_count']/max(photo_df['comment_count']) #normalizing comment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df.loc[:,('likes_normal')] = photo_df.loc[:,('likes_count')]/max(photo_df['likes_count']) #normalizing likes count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engagement score = .4*# likes (normalized) + .6*# comments (normalized). \n",
    "photo_df.loc[:,('engagement_score')] = (0.4*photo_df.loc[:,('likes_normal')]) + (0.6*photo_df.loc[:,('comment_normal')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = photo_df['engagement_score'].median()\n",
    "photo_df['engagement'] = np.where(photo_df['engagement_score']>= med, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    282\n",
       "0    281\n",
       "Name: engagement, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_df['engagement'].value_counts() # no. of high and low engagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#photo_df.to_csv('HW2_postTaskA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Image Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud\n",
    "!pip install google-cloud-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.cloud import vision\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df=pd.read_csv('HW2_karan_postTaskA.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df=photo_df.reset_index(drop=True)\n",
    "photo_df_temp=photo_df\n",
    "photo_df_temp.head()\n",
    "photo_df_temp=photo_df_temp.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name=[]\n",
    "labels=[]\n",
    "image_paths = []\n",
    "counter=0\n",
    "\n",
    "for each_img in photo_df_temp.image_link:\n",
    "    image_paths.append(each_img)\n",
    "    file_name.append(str(photo_df_temp.image_link.index[counter]+1) + \".jpg\")\n",
    "    counter+=1\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "image = vision.types.Image()   \n",
    "\n",
    "def getlabelsforRemoteImage(uri):\n",
    "    \"\"\"Detects labels in the file located in Google Cloud Storage or on the\n",
    "    Web.\"\"\"\n",
    "    labels_list=[]\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    \n",
    "    for label in labels:\n",
    "        labels_list.append(label.description)\n",
    "    print(uri)\n",
    "    print(labels_list)\n",
    "    return(labels_list)\n",
    "\n",
    "for i in image_paths:\n",
    "    labels.append(getlabelsforRemoteImage(i))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "photo_df_temp['labels']=pd.Series(labels)    \n",
    "photo_df_temp['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#photo_df_temp.to_csv('with_labels.csv') #saving the labels to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>post_link</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>caption</th>\n",
       "      <th>is_video</th>\n",
       "      <th>image_link</th>\n",
       "      <th>comment_normal</th>\n",
       "      <th>likes_normal</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>engagement</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://instagram.com/p/B44MXP-gNxy/</td>\n",
       "      <td>209</td>\n",
       "      <td>79912</td>\n",
       "      <td>Photo by Keith Ladzinski @ladzinski | With a l...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/93c...</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.033486</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>0</td>\n",
       "      <td>['Tree', 'Sky', 'Blue', 'Woody plant', 'Plant'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://instagram.com/p/B433BqzAGIf/</td>\n",
       "      <td>685</td>\n",
       "      <td>178480</td>\n",
       "      <td>Photo by Cristina Mittermeier @Mitty | Did you...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/235...</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.074790</td>\n",
       "      <td>0.037115</td>\n",
       "      <td>0</td>\n",
       "      <td>['People in nature', 'Photograph', 'Black', 'B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://instagram.com/p/B43ibepIaV0/</td>\n",
       "      <td>511</td>\n",
       "      <td>110287</td>\n",
       "      <td>Photo by @jodicobbphoto | Heartbreaking floods...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/ca0...</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.046214</td>\n",
       "      <td>0.023856</td>\n",
       "      <td>0</td>\n",
       "      <td>['Reflection', 'Water', 'Reflecting pool', 'Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>https://instagram.com/p/B43OGVdD9Rx/</td>\n",
       "      <td>525</td>\n",
       "      <td>253331</td>\n",
       "      <td>Photos by Stephen Alvarez @salvarezphoto | My ...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/d98...</td>\n",
       "      <td>0.009196</td>\n",
       "      <td>0.106155</td>\n",
       "      <td>0.047979</td>\n",
       "      <td>0</td>\n",
       "      <td>['Sky', 'Galaxy', 'Night', 'Astronomical objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>https://instagram.com/p/B425rKvjVLJ/</td>\n",
       "      <td>826</td>\n",
       "      <td>141166</td>\n",
       "      <td>Photo by @dina_litovsky | These are portraits ...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/b7f...</td>\n",
       "      <td>0.014468</td>\n",
       "      <td>0.059154</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0</td>\n",
       "      <td>['Lady', 'Beauty', 'Lip', 'Fashion', 'Photo sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1                             post_link  \\\n",
       "0           0             0  https://instagram.com/p/B44MXP-gNxy/   \n",
       "1           1             1  https://instagram.com/p/B433BqzAGIf/   \n",
       "2           2             2  https://instagram.com/p/B43ibepIaV0/   \n",
       "3           3             3  https://instagram.com/p/B43OGVdD9Rx/   \n",
       "4           4             4  https://instagram.com/p/B425rKvjVLJ/   \n",
       "\n",
       "   comment_count  likes_count  \\\n",
       "0            209        79912   \n",
       "1            685       178480   \n",
       "2            511       110287   \n",
       "3            525       253331   \n",
       "4            826       141166   \n",
       "\n",
       "                                             caption  is_video  \\\n",
       "0  Photo by Keith Ladzinski @ladzinski | With a l...     False   \n",
       "1  Photo by Cristina Mittermeier @Mitty | Did you...     False   \n",
       "2  Photo by @jodicobbphoto | Heartbreaking floods...     False   \n",
       "3  Photos by Stephen Alvarez @salvarezphoto | My ...     False   \n",
       "4  Photo by @dina_litovsky | These are portraits ...     False   \n",
       "\n",
       "                                          image_link  comment_normal  \\\n",
       "0  https://instagram.fftw1-1.fna.fbcdn.net/vp/93c...        0.003661   \n",
       "1  https://instagram.fftw1-1.fna.fbcdn.net/vp/235...        0.011998   \n",
       "2  https://instagram.fftw1-1.fna.fbcdn.net/vp/ca0...        0.008950   \n",
       "3  https://instagram.fftw1-1.fna.fbcdn.net/vp/d98...        0.009196   \n",
       "4  https://instagram.fftw1-1.fna.fbcdn.net/vp/b7f...        0.014468   \n",
       "\n",
       "   likes_normal  engagement_score  engagement  \\\n",
       "0      0.033486          0.015591           0   \n",
       "1      0.074790          0.037115           0   \n",
       "2      0.046214          0.023856           0   \n",
       "3      0.106155          0.047979           0   \n",
       "4      0.059154          0.032342           0   \n",
       "\n",
       "                                              labels  \n",
       "0  ['Tree', 'Sky', 'Blue', 'Woody plant', 'Plant'...  \n",
       "1  ['People in nature', 'Photograph', 'Black', 'B...  \n",
       "2  ['Reflection', 'Water', 'Reflecting pool', 'Ar...  \n",
       "3  ['Sky', 'Galaxy', 'Night', 'Astronomical objec...  \n",
       "4  ['Lady', 'Beauty', 'Lip', 'Fashion', 'Photo sh...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_df_temp = pd.read_csv('with_labels.csv')\n",
    "photo_df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(doce):\n",
    "\n",
    "    X_train, X_test, y_train,y_test = train_test_split(doce,photo_df_temp['engagement'] ,test_size= 0.2, random_state=18)\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english',use_idf=True)\n",
    "\n",
    "    fitted_vectorizer=tfidf_vectorizer.fit(X_train)\n",
    "    tfidf_vectorizer_vectors=fitted_vectorizer.transform(X_train)\n",
    "\n",
    "    test_features = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "        #call the labels one column at a time so we can run the classifier on them\n",
    "    train_target = y_train\n",
    "    test_target = y_test\n",
    "    classifier = LogisticRegression(solver='sag', C=10)\n",
    "\n",
    "    y_train= y_train.astype('int')\n",
    "    y_test = y_test.astype('int')\n",
    "\n",
    "    classifier=classifier.fit(tfidf_vectorizer_vectors, train_target)\n",
    "\n",
    "    y_pred=classifier.predict(test_features)\n",
    "    print(confusion_matrix(test_target, y_pred))\n",
    "    print(classification_report(test_target, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ['Tree', 'Sky', 'Blue', 'Woody plant', 'Plant'...\n",
       "1      ['People in nature', 'Photograph', 'Black', 'B...\n",
       "2      ['Reflection', 'Water', 'Reflecting pool', 'Ar...\n",
       "3      ['Sky', 'Galaxy', 'Night', 'Astronomical objec...\n",
       "4      ['Lady', 'Beauty', 'Lip', 'Fashion', 'Photo sh...\n",
       "5      ['Visual effect lighting', 'Technology', 'Disp...\n",
       "6      ['Tiger', 'Wildlife', 'Vertebrate', 'Bengal ti...\n",
       "7      ['Wave', 'Ocean', 'Surfing Equipment', 'Surfin...\n",
       "8      ['Water', 'Nature', 'Black-and-white', 'Atmosp...\n",
       "9      ['Army', 'Soldier', 'Military', 'Military unif...\n",
       "10     ['Arctic', 'Glacial landform', 'Natural enviro...\n",
       "11     ['Orange', 'Silhouette', 'Yellow', 'Backlighti...\n",
       "12     ['Face', 'Facial expression', 'Wrinkle', 'Fore...\n",
       "13     ['Grass', 'Pasture', 'Wildlife', 'Grass family...\n",
       "14                   ['Adventure', 'Recreation', 'Fawn']\n",
       "15     ['Design', 'Textile', 'Colorfulness', 'Pattern...\n",
       "16     ['Hair', 'Face', 'Beauty', 'Lip', 'Lady', 'Hai...\n",
       "17     ['Mammal', 'Hyena', 'Vertebrate', 'Wildlife', ...\n",
       "18     ['Sky', 'Nature', 'Horizon', 'Atmosphere', 'At...\n",
       "19                                             ['Night']\n",
       "20     ['Sky', 'Water', 'Blue', 'Sea', 'Atmosphere', ...\n",
       "21     ['Sky', 'Cloud', 'White', 'Black', 'Black-and-...\n",
       "22     ['People', 'Human', 'Adaptation', 'Smile', 'Te...\n",
       "23     ['Green', 'Sky', 'Aurora', 'Grass', 'Tree', 'L...\n",
       "24     ['Blue', 'Fish', 'Fish', 'Organism', 'Water', ...\n",
       "25     ['Youth', 'Community', 'Event', 'Adaptation', ...\n",
       "26     ['Furniture', 'Room', 'Bed', 'Bedroom', 'Texti...\n",
       "27     ['Wildlife', 'Hyena', 'Grassland', 'Natural la...\n",
       "28     ['Face', 'Skin', 'People', 'Nose', 'Head', 'Wr...\n",
       "29     ['Jungle', 'Natural environment', 'Tree', 'Rai...\n",
       "                             ...                        \n",
       "533    ['Reflection', 'Rear-view mirror', 'Automotive...\n",
       "534    ['Yellow', 'Water', 'Infrastructure', 'Geologi...\n",
       "535    ['Bird', 'Water bird', 'Duck', 'Mergus', 'Beak...\n",
       "536    ['Moon', 'Full moon', 'Sky', 'Celestial event'...\n",
       "537    ['Body of water', 'Water', 'Sky', 'Sea', 'Blue...\n",
       "538    ['Horse', 'Steppe', 'Ecoregion', 'Sky', 'Recre...\n",
       "539    ['Mountainous landforms', 'Mountain', 'Adventu...\n",
       "540    ['Night', 'Light', 'Lighting', 'House', 'Sky',...\n",
       "541    ['Vertebrate', 'Herd', 'Wildlife', 'Mammal', '...\n",
       "542    ['Reptile', 'Gecko', 'Vertebrate', 'Lizard', '...\n",
       "543    ['Sky', 'Campfire', 'Heat', 'Fire', 'Night', '...\n",
       "544    ['Geological phenomenon', 'Lava', 'Lava plain'...\n",
       "545            ['Winter', 'Flame', 'Sky', 'Ice', 'Snow']\n",
       "546    ['Grassland', 'Field', 'Plain', 'Natural envir...\n",
       "547    ['Vegetation', 'Tree', 'Plant', 'Water', 'Leaf...\n",
       "548    ['Marine biology', 'Fish', 'Bronze hammerhead ...\n",
       "549    ['Sea turtle', 'Olive ridley sea turtle', 'Log...\n",
       "550    ['Sky', 'Nature', 'Mountainous landforms', 'At...\n",
       "551    ['Sky', 'Star', 'Atmospheric phenomenon', 'Ast...\n",
       "552    ['Elephant', 'African elephant', 'Elephants an...\n",
       "553    ['Mammal', 'Vertebrate', 'Common chimpanzee', ...\n",
       "554    ['Bonfire', 'Fire', 'Flame', 'Heat', 'Campfire...\n",
       "555    ['Mountainous landforms', 'Mountain', 'Sound',...\n",
       "556    ['Beauty', 'Snapshot', 'Summer', 'Footwear', '...\n",
       "557    ['Facial expression', 'Tooth', 'Mouth', 'Snout...\n",
       "558    ['Public space', 'Building', 'Tourism', 'City'...\n",
       "559    ['Mammal', 'Vertebrate', 'Macaque', 'Old world...\n",
       "560    ['Dog', 'Vertebrate', 'Mammal', 'Canidae', 'Ca...\n",
       "561    ['Green', 'Lady', 'Beauty', 'Sitting', 'Botany...\n",
       "562    ['Underwater', 'Marine biology', 'Organism', '...\n",
       "Name: labels, Length: 563, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " photo_df_temp['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-cfea32908dd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlabel_document\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_document\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-2977d5f16d2f>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(doce)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtfidf_vectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_idf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mfitted_vectorizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtfidf_vectorizer_vectors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfitted_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1629\u001b[0m         \"\"\"\n\u001b[0;32m   1630\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m-> 1058\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[0;32m    990\u001b[0m                                  \" contain stop words\")\n\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "label_document=[]\n",
    "for each_label in photo_df_temp['labels']:\n",
    "    \n",
    "    labels=''\n",
    "    \n",
    "    for each_word in each_label:\n",
    "        labels=labels+ each_word + ' '\n",
    "    label_document.append(labels)    \n",
    "\n",
    "classify(label_document) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_document=[]\n",
    "for each_caption in photo_df_temp['caption']:\n",
    "    caption='' \n",
    "    caption=caption+ each_caption + ' '\n",
    "    caption_document.append(caption)  \n",
    "\n",
    "classify(caption_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    label_document=''\n",
    "    for each_word in row:\n",
    "        label_document= label_document+ ' ' + each_word \n",
    "    return label_document \n",
    "\n",
    "photo_df_temp['labels']=photo_df_temp['labels'].apply(get_label)\n",
    "photo_df_temp['caption_label']=photo_df_temp['caption'] + photo_df_temp['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "caption_label_document=[]\n",
    "for each_caption in photo_df_temp['caption_label']:\n",
    "    caption='' \n",
    "    caption=caption+ each_caption + ' '\n",
    "    caption_label_document.append(caption)  \n",
    "\n",
    "classify(caption_label_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C - Topic Modeling (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "df = pd.read_csv('with_labels.csv', error_bad_lines=False)\n",
    "df=photo_df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Tree', 'Sky', 'Blue', 'Woody plant', 'Plant'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['People in nature', 'Photograph', 'Black', 'B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Reflection', 'Water', 'Reflecting pool', 'Ar...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Sky', 'Galaxy', 'Night', 'Astronomical objec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Lady', 'Beauty', 'Lip', 'Fashion', 'Photo sh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['Visual effect lighting', 'Technology', 'Disp...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['Tiger', 'Wildlife', 'Vertebrate', 'Bengal ti...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['Wave', 'Ocean', 'Surfing Equipment', 'Surfin...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['Water', 'Nature', 'Black-and-white', 'Atmosp...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['Army', 'Soldier', 'Military', 'Military unif...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              labels  index\n",
       "0  ['Tree', 'Sky', 'Blue', 'Woody plant', 'Plant'...      0\n",
       "1  ['People in nature', 'Photograph', 'Black', 'B...      1\n",
       "2  ['Reflection', 'Water', 'Reflecting pool', 'Ar...      2\n",
       "3  ['Sky', 'Galaxy', 'Night', 'Astronomical objec...      3\n",
       "4  ['Lady', 'Beauty', 'Lip', 'Fashion', 'Photo sh...      4\n",
       "5  ['Visual effect lighting', 'Technology', 'Disp...      5\n",
       "6  ['Tiger', 'Wildlife', 'Vertebrate', 'Bengal ti...      6\n",
       "7  ['Wave', 'Ocean', 'Surfing Equipment', 'Surfin...      7\n",
       "8  ['Water', 'Nature', 'Black-and-white', 'Atmosp...      8\n",
       "9  ['Army', 'Soldier', 'Military', 'Military unif...      9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1)\n",
    "\n",
    "data_labels = df[['labels']]\n",
    "data_labels['index'] = data_labels.index\n",
    "print(len(data_labels))\n",
    "data_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming, Lemmatizing and Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nithi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer \n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "[\"['Field',\", \"'Crop',\", \"'Agriculture',\", \"'Plantation',\", \"'Farm',\", \"'Cash\", \"crop',\", \"'Sky',\", \"'Morning',\", \"'Plant',\", \"'Rural\", \"area']\"]\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['field', 'crop', 'agriculture', 'plantation', 'farm', 'cash', 'crop', 'sky', 'morning', 'plant', 'rural', 'area']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [tree, sky, blue, woody, plant, plant, night, ...\n",
       "1    [people, nature, photograph, black, black, whi...\n",
       "2    [reflection, water, reflect, pool, architectur...\n",
       "3    [sky, galaxy, night, astronomical, object, atm...\n",
       "4    [lady, beauty, lip, fashion, photo, shoot, arm...\n",
       "5    [visual, effect, light, technology, display, d...\n",
       "6    [tiger, wildlife, vertebrate, bengal, tiger, s...\n",
       "7    [wave, ocean, surf, equipment, surf, sea, surf...\n",
       "8    [water, nature, black, white, atmospheric, phe...\n",
       "9    [army, soldier, military, military, uniform, t...\n",
       "Name: labels, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sample = data_labels[data_labels['index'] == 200].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))\n",
    "\n",
    "processed_docs = data_labels['labels'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 blue\n",
      "1 branch\n",
      "2 electric\n",
      "3 midnight\n",
      "4 night\n",
      "5 plant\n",
      "6 sky\n",
      "7 tree\n",
      "8 trunk\n",
      "9 woody\n",
      "10 arm\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=7, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim doc2bow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sky',\n",
       " 'pasture',\n",
       " 'nature',\n",
       " 'horse',\n",
       " 'grassland',\n",
       " 'graze',\n",
       " 'natural',\n",
       " 'landscape',\n",
       " 'natural',\n",
       " 'environment',\n",
       " 'grass',\n",
       " 'cloud']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[310]\n",
    "\n",
    "processed_docs[310]\n",
    "\n",
    "#To output words and their corresponding frequency\n",
    "\n",
    "#bow_doc_310 = bow_corpus[310]\n",
    "#for i in range(len(bow_doc_310)):\n",
    "    #print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_310[i][0], \n",
    "     #                                          dictionary[bow_doc_310[i][0]], \n",
    "#bow_doc_310[i][1]))\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF -- needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.572707854477416),\n",
      " (1, 0.3926000982525617),\n",
      " (2, 0.2723570578890986),\n",
      " (3, 0.4899790534091618),\n",
      " (4, 0.11633249607202363),\n",
      " (5, 0.20564533405203733),\n",
      " (6, 0.3844343681963)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=4, id2word=dictionary, passes=8, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.074*\"water\" + 0.070*\"sea\" + 0.049*\"natural\" + 0.038*\"sky\" + 0.034*\"fish\" + 0.032*\"ocean\" + 0.032*\"marine\" + 0.031*\"turtle\" + 0.031*\"environment\" + 0.025*\"underwater\"\n",
      "Topic: 1 \n",
      "Words: 0.059*\"wildlife\" + 0.047*\"animal\" + 0.040*\"plant\" + 0.038*\"terrestrial\" + 0.038*\"photography\" + 0.032*\"vertebrate\" + 0.030*\"tree\" + 0.029*\"bird\" + 0.025*\"elephant\" + 0.025*\"mammal\"\n",
      "Topic: 2 \n",
      "Words: 0.062*\"photography\" + 0.039*\"fun\" + 0.035*\"human\" + 0.035*\"people\" + 0.034*\"adaptation\" + 0.033*\"event\" + 0.032*\"dog\" + 0.026*\"smile\" + 0.026*\"child\" + 0.025*\"room\"\n",
      "Topic: 3 \n",
      "Words: 0.085*\"sky\" + 0.051*\"phenomenon\" + 0.042*\"mountain\" + 0.038*\"landscape\" + 0.029*\"atmospheric\" + 0.029*\"light\" + 0.028*\"night\" + 0.026*\"landforms\" + 0.025*\"atmosphere\" + 0.025*\"mountainous\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-10 words loaded for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic words: 0 \n",
      "Words: ['water', 'sea', 'natural', 'sky', 'fish', 'ocean', 'marine', 'turtle', 'environment', 'underwater']\n",
      "Topic words: 1 \n",
      "Words: ['wildlife', 'animal', 'plant', 'terrestrial', 'photography', 'vertebrate', 'tree', 'bird', 'elephant', 'mammal']\n",
      "Topic words: 2 \n",
      "Words: ['photography', 'fun', 'human', 'people', 'adaptation', 'event', 'dog', 'smile', 'child', 'room']\n",
      "Topic words: 3 \n",
      "Words: ['sky', 'phenomenon', 'mountain', 'landscape', 'atmospheric', 'light', 'night', 'landforms', 'atmosphere', 'mountainous']\n"
     ]
    }
   ],
   "source": [
    "x=lda_model.show_topics()\n",
    "\n",
    "def Convert(string): \n",
    "    li = list(string.split(\"  \")) \n",
    "    return li \n",
    "\n",
    "twords={}\n",
    "for topic,word in x:\n",
    "    twords[topic]=Convert(re.sub('[^A-Za-z ]+','', word))\n",
    "    print('Topic words:',topic,'\\nWords:',twords[topic])\n",
    "    \n",
    "terms_df = pd.DataFrame([twords])\n",
    "terms_df = terms_df.transpose()\n",
    "terms_df.index.name = 'Topic'\n",
    "terms_df.columns = ['Words']\n",
    "terms_df.to_csv('words_loading_on_topics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation \n",
    "\n",
    "#### This was just for manual verification wherein we changed index number everytime manually and checked topic generated for a set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people',\n",
       " 'black',\n",
       " 'child',\n",
       " 'lady',\n",
       " 'skin',\n",
       " 'adaptation',\n",
       " 'human',\n",
       " 'smile',\n",
       " 'fun',\n",
       " 'photography']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score 0.9307007789611816 \n",
      "Topic: 2\n",
      "\n",
      "Score 0.023663941770792007 \n",
      "Topic: 1\n",
      "\n",
      "Score 0.022875169292092323 \n",
      "Topic: 3\n",
      "\n",
      "Score 0.022760048508644104 \n",
      "Topic: 0\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[300]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore {} \\nTopic: {}\".format(score, index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(bow_corpus)):\n",
    "    for index, score in sorted(lda_model[bow_corpus[i]], key=lambda tup: -1*tup[1]):\n",
    "        arr = \"Topic \"+ str(index)\n",
    "        data_labels.loc[i,arr]= score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>index</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>['People', 'Black', 'Child', 'Lady', 'Skin', '...</td>\n",
       "      <td>300</td>\n",
       "      <td>0.022875</td>\n",
       "      <td>0.023657</td>\n",
       "      <td>0.02276</td>\n",
       "      <td>0.930708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                labels  index   Topic 3  \\\n",
       "300  ['People', 'Black', 'Child', 'Lady', 'Skin', '...    300  0.022875   \n",
       "\n",
       "      Topic 1  Topic 0   Topic 2  \n",
       "300  0.023657  0.02276  0.930708  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels[300:301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>sky, phenomenon, mountain, landscape, atmosphe...</td>\n",
       "      <td>[tree, sky, blue, woody, plant, plant, night, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5955</td>\n",
       "      <td>wildlife, animal, plant, terrestrial, photogra...</td>\n",
       "      <td>[people, nature, photograph, black, black, whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7151</td>\n",
       "      <td>water, sea, natural, sky, fish, ocean, marine,...</td>\n",
       "      <td>[reflection, water, reflect, pool, architectur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>sky, phenomenon, mountain, landscape, atmosphe...</td>\n",
       "      <td>[sky, galaxy, night, astronomical, object, atm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>photography, fun, human, people, adaptation, e...</td>\n",
       "      <td>[lady, beauty, lip, fashion, photo, shoot, arm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>sky, phenomenon, mountain, landscape, atmosphe...</td>\n",
       "      <td>[visual, effect, light, technology, display, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9362</td>\n",
       "      <td>wildlife, animal, plant, terrestrial, photogra...</td>\n",
       "      <td>[tiger, wildlife, vertebrate, bengal, tiger, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8908</td>\n",
       "      <td>water, sea, natural, sky, fish, ocean, marine,...</td>\n",
       "      <td>[wave, ocean, surf, equipment, surf, sea, surf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>wildlife, animal, plant, terrestrial, photogra...</td>\n",
       "      <td>[water, nature, black, white, atmospheric, phe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>water, sea, natural, sky, fish, ocean, marine,...</td>\n",
       "      <td>[army, soldier, military, military, uniform, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             3.0              0.4828   \n",
       "1            1             1.0              0.5955   \n",
       "2            2             0.0              0.7151   \n",
       "3            3             3.0              0.9245   \n",
       "4            4             2.0              0.8741   \n",
       "5            5             3.0              0.6250   \n",
       "6            6             1.0              0.9362   \n",
       "7            7             0.0              0.8908   \n",
       "8            8             1.0              0.5772   \n",
       "9            9             0.0              0.2500   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  sky, phenomenon, mountain, landscape, atmosphe...   \n",
       "1  wildlife, animal, plant, terrestrial, photogra...   \n",
       "2  water, sea, natural, sky, fish, ocean, marine,...   \n",
       "3  sky, phenomenon, mountain, landscape, atmosphe...   \n",
       "4  photography, fun, human, people, adaptation, e...   \n",
       "5  sky, phenomenon, mountain, landscape, atmosphe...   \n",
       "6  wildlife, animal, plant, terrestrial, photogra...   \n",
       "7  water, sea, natural, sky, fish, ocean, marine,...   \n",
       "8  wildlife, animal, plant, terrestrial, photogra...   \n",
       "9  water, sea, natural, sky, fish, ocean, marine,...   \n",
       "\n",
       "                                                Text  \n",
       "0  [tree, sky, blue, woody, plant, plant, night, ...  \n",
       "1  [people, nature, photograph, black, black, whi...  \n",
       "2  [reflection, water, reflect, pool, architectur...  \n",
       "3  [sky, galaxy, night, astronomical, object, atm...  \n",
       "4  [lady, beauty, lip, fashion, photo, shoot, arm...  \n",
       "5  [visual, effect, light, technology, display, d...  \n",
       "6  [tiger, wildlife, vertebrate, bengal, tiger, s...  \n",
       "7  [wave, ocean, surf, equipment, surf, sea, surf...  \n",
       "8  [water, nature, black, white, atmospheric, phe...  \n",
       "9  [army, soldier, military, military, uniform, t...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This bit gives out the best topic match for each document and the corresponding score\n",
    "def format_topics_sentences(lda_model=None, corpus=bow_corpus, texts=processed_docs):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(lda_model[bow_corpus]):\n",
    "        row = row_list[0] if lda_model.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = lda_model.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(lda_model, corpus=bow_corpus, texts=processed_docs)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_labels['image_URL'] = df['image_link']\n",
    "\n",
    "cols = ['image_URL','labels','index','Topic 1','Topic 2','Topic 3']\n",
    "data_labels[cols].to_csv('topics_and_weights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engagement scores vs Topic Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25    0.045992\n",
       "0.50    0.069458\n",
       "0.75    0.097723\n",
       "Name: engagement_score, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels['engagement_score']=df['engagement_score']\n",
    "data_labels.engagement_score.quantile([0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into two quartiles for the lowest and highest engageent scores\n",
    "quart_25 = data_labels[data_labels['engagement_score']<0.045992] #lowest\n",
    "quart_75 = data_labels[data_labels['engagement_score']>0.097723] #highest\n",
    "\n",
    "#Average of topic weights in each of these quartiles\n",
    "avg_low = pd.DataFrame(quart_25[['Topic 0','Topic 1','Topic 2','Topic 3']].mean())\n",
    "avg_low = avg_low.transpose()\n",
    "\n",
    "#print(avg_low)\n",
    "\n",
    "\n",
    "avg_high = pd.DataFrame(quart_75[['Topic 0','Topic 1','Topic 2','Topic 3']].mean())\n",
    "avg_high = avg_high.transpose()\n",
    "#print(avg_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marine</th>\n",
       "      <th>Wildlife</th>\n",
       "      <th>Human</th>\n",
       "      <th>Terrains</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engagement_levels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Low Engagement</th>\n",
       "      <td>0.119040</td>\n",
       "      <td>0.164306</td>\n",
       "      <td>0.431617</td>\n",
       "      <td>0.285037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High Engagement</th>\n",
       "      <td>0.272248</td>\n",
       "      <td>0.340390</td>\n",
       "      <td>0.139350</td>\n",
       "      <td>0.248011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Marine  Wildlife     Human  Terrains\n",
       "Engagement_levels                                        \n",
       "Low Engagement     0.119040  0.164306  0.431617  0.285037\n",
       "High Engagement    0.272248  0.340390  0.139350  0.248011"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engagement_scores_high_and_low = avg_low.append(avg_high,ignore_index=True)\n",
    "engagement_scores_high_and_low['Engagement_levels'] = ['Low Engagement','High Engagement']\n",
    "engagement_scores_high_and_low.set_index('Engagement_levels',inplace=True)\n",
    "engagement_scores_high_and_low.rename(columns = {\"Topic 0\": \"Marine\", \"Topic 1\": \"Wildlife\", \"Topic 2\": \"Human\", \"Topic 3\": \"Terrains\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1614818270360183922917823935\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1614818270360183922917823935_data = {\"mdsDat\": {\"x\": [-0.10416625202213814, -0.20662741692873948, 0.028457221112705877, 0.2823364478381714], \"y\": [-0.22375163535095177, 0.11436474042503152, 0.12037371503049779, -0.010986820104577662], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [27.970813751220703, 27.869903564453125, 25.516807556152344, 18.642465591430664]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Freq\": [91.0, 115.0, 77.0, 57.0, 174.0, 71.0, 112.0, 45.0, 43.0, 82.0, 41.0, 61.0, 40.0, 38.0, 39.0, 31.0, 43.0, 27.0, 32.0, 34.0, 37.0, 37.0, 61.0, 40.0, 31.0, 29.0, 64.0, 23.0, 31.0, 38.0, 36.889007568359375, 19.653573989868164, 31.31157112121582, 12.794000625610352, 12.788203239440918, 12.788125991821289, 15.524852752685547, 19.132356643676758, 10.917096138000488, 12.625638961791992, 8.981402397155762, 8.974823951721191, 9.863046646118164, 9.85932445526123, 8.959089279174805, 35.56167221069336, 7.989356517791748, 17.714567184448242, 7.969968795776367, 12.339798927307129, 36.95486831665039, 7.915228843688965, 7.021900653839111, 7.01988410949707, 6.964445114135742, 13.893007278442383, 64.1869888305664, 31.14522361755371, 8.475281715393066, 53.684226989746094, 12.533852577209473, 33.33485412597656, 25.267845153808594, 24.286653518676758, 15.298547744750977, 107.47026062011719, 48.29716110229492, 28.776443481445312, 27.34625244140625, 20.85711097717285, 14.526717185974121, 12.024064064025879, 18.13219451904297, 14.873620986938477, 12.76928997039795, 42.434295654296875, 40.53165054321289, 39.60874557495117, 38.59800720214844, 30.249740600585938, 31.126754760742188, 28.355695724487305, 28.347089767456055, 87.70341491699219, 18.05776023864746, 13.356807708740234, 40.922481536865234, 12.427061080932617, 10.56116008758545, 11.432419776916504, 10.534753799438477, 11.382960319519043, 9.621673583984375, 9.524192810058594, 8.621878623962402, 8.566774368286133, 8.518311500549316, 7.662844657897949, 9.283358573913574, 6.701581954956055, 7.379578590393066, 7.872821807861328, 7.733203887939453, 93.22821044921875, 12.53592586517334, 61.57489013671875, 19.463659286499023, 25.32590103149414, 13.271862983703613, 27.290910720825195, 19.436189651489258, 48.34659194946289, 22.387619018554688, 31.12432098388672, 13.802006721496582, 16.285213470458984, 12.967635154724121, 11.548710823059082, 33.60566711425781, 28.73368263244629, 54.864620208740234, 43.763389587402344, 17.30608558654785, 15.424216270446777, 13.583832740783691, 12.591506004333496, 12.58842658996582, 11.636330604553223, 11.48914623260498, 8.801423072814941, 10.541168212890625, 12.292791366577148, 7.7971062660217285, 9.459813117980957, 6.87593936920166, 68.23969268798828, 20.577800750732422, 7.92293119430542, 9.669689178466797, 6.651139259338379, 7.810966968536377, 10.571699142456055, 36.95370101928711, 5.589008331298828, 5.587953567504883, 46.492061614990234, 7.567407608032227, 13.043624877929688, 23.681060791015625, 13.024188995361328, 22.060012817382812, 27.048913955688477, 28.625431060791016, 34.75602722167969, 43.53980255126953, 27.63060760498047, 14.455282211303711, 15.677334785461426, 12.907977104187012, 14.213373184204102, 18.104015350341797, 16.292545318603516, 15.144563674926758, 27.225908279418945, 22.24721336364746, 21.114606857299805, 15.48112678527832, 12.740987777709961, 21.801692962646484, 16.33130645751953, 13.568258285522461, 10.844749450683594, 9.831513404846191, 11.618888854980469, 10.720499992370605, 10.719923973083496, 9.810751914978027, 29.410964965820312, 7.906482219696045, 8.745990753173828, 6.98740291595459, 8.734723091125488, 11.352663040161133, 11.342611312866211, 6.971226692199707, 8.702845573425293, 6.883596420288086, 29.124338150024414, 6.835580348968506, 8.465378761291504, 10.07003116607666, 13.31086254119873, 32.57918930053711, 14.208534240722656, 28.079776763916016, 13.18148136138916, 17.553131103515625, 52.16535186767578, 15.043327331542969, 15.780628204345703, 28.754600524902344, 12.320725440979004, 10.526040077209473], \"Term\": [\"sea\", \"water\", \"wildlife\", \"animal\", \"sky\", \"phenomenon\", \"photography\", \"terrestrial\", \"fish\", \"natural\", \"marine\", \"mountain\", \"turtle\", \"fun\", \"environment\", \"human\", \"ocean\", \"dog\", \"people\", \"bird\", \"light\", \"event\", \"adaptation\", \"atmospheric\", \"underwater\", \"elephant\", \"plant\", \"smile\", \"ice\", \"night\", \"light\", \"area\", \"atmosphere\", \"space\", \"astronomical\", \"object\", \"build\", \"morning\", \"history\", \"city\", \"urban\", \"site\", \"road\", \"infrastructure\", \"ancient\", \"night\", \"mist\", \"range\", \"game\", \"even\", \"atmospheric\", \"heat\", \"star\", \"rural\", \"backlighting\", \"ridge\", \"phenomenon\", \"mountainous\", \"landmark\", \"mountain\", \"highland\", \"landforms\", \"architecture\", \"geological\", \"hill\", \"sky\", \"landscape\", \"cloud\", \"tree\", \"nature\", \"tourism\", \"yellow\", \"natural\", \"rock\", \"photography\", \"fish\", \"marine\", \"turtle\", \"environment\", \"ice\", \"underwater\", \"biology\", \"shark\", \"sea\", \"arctic\", \"cap\", \"ocean\", \"polar\", \"reef\", \"river\", \"cartilaginous\", \"resources\", \"fin\", \"boat\", \"lake\", \"fur\", \"body\", \"calm\", \"snow\", \"primate\", \"watercourse\", \"beach\", \"great\", \"water\", \"wave\", \"natural\", \"green\", \"organism\", \"reflection\", \"nature\", \"blue\", \"sky\", \"cloud\", \"landscape\", \"horizon\", \"mammal\", \"wilderness\", \"forest\", \"bird\", \"elephant\", \"animal\", \"terrestrial\", \"monochrome\", \"felidae\", \"beak\", \"elephants\", \"mammoths\", \"cat\", \"safari\", \"african\", \"indian\", \"woody\", \"leaf\", \"aerial\", \"big\", \"wildlife\", \"horse\", \"savanna\", \"branch\", \"botany\", \"whisker\", \"lion\", \"vertebrate\", \"oceanic\", \"coastal\", \"plant\", \"work\", \"formation\", \"black\", \"geology\", \"white\", \"rock\", \"mammal\", \"tree\", \"photography\", \"adaptation\", \"snout\", \"grass\", \"carnivore\", \"organism\", \"sky\", \"water\", \"landscape\", \"dog\", \"smile\", \"room\", \"design\", \"group\", \"child\", \"canidae\", \"lady\", \"breed\", \"dress\", \"tradition\", \"skin\", \"portrait\", \"sit\", \"human\", \"furniture\", \"hand\", \"scale\", \"head\", \"performance\", \"beauty\", \"tribe\", \"face\", \"headgear\", \"people\", \"interior\", \"fashion\", \"happy\", \"crowd\", \"fun\", \"leisure\", \"event\", \"hair\", \"art\", \"photography\", \"reptile\", \"sport\", \"adaptation\", \"tourism\", \"carnivore\"], \"Total\": [91.0, 115.0, 77.0, 57.0, 174.0, 71.0, 112.0, 45.0, 43.0, 82.0, 41.0, 61.0, 40.0, 38.0, 39.0, 31.0, 43.0, 27.0, 32.0, 34.0, 37.0, 37.0, 61.0, 40.0, 31.0, 29.0, 64.0, 23.0, 31.0, 38.0, 37.86771011352539, 20.387937545776367, 32.985408782958984, 13.585695266723633, 13.585124015808105, 13.585126876831055, 16.494478225708008, 20.371400833129883, 11.644229888916016, 13.579654693603516, 9.701316833496094, 9.701130867004395, 10.67072582244873, 10.670655250549316, 9.700582504272461, 38.78438186645508, 8.72941780090332, 19.397287368774414, 8.728821754455566, 13.56988525390625, 40.689212799072266, 8.727288246154785, 7.757926940917969, 7.7576069831848145, 7.7565693855285645, 15.514822006225586, 71.7107925415039, 34.8785400390625, 9.684183120727539, 61.96033477783203, 14.515589714050293, 41.591670989990234, 31.016334533691406, 30.015743255615234, 18.364147186279297, 174.82815551757812, 97.73709869384766, 52.63295364379883, 75.90784454345703, 59.11434555053711, 30.867897033691406, 18.329477310180664, 82.33824920654297, 48.862667083740234, 112.43057250976562, 43.206851959228516, 41.32943344116211, 40.39043045043945, 39.45258331298828, 31.00116729736328, 31.941627502441406, 29.123920440673828, 29.124454498291016, 91.13894653320312, 18.795886993408203, 14.102063179016113, 43.235137939453125, 13.162744522094727, 11.284835815429688, 12.224894523620605, 11.285493850708008, 12.22575569152832, 10.345999717712402, 10.348259925842285, 9.408700942993164, 9.410280227661133, 9.41131591796875, 8.470699310302734, 10.352004051208496, 7.531118392944336, 8.474812507629395, 9.424599647521973, 9.43317985534668, 115.00215911865234, 16.02730941772461, 82.33824920654297, 26.49163055419922, 40.650150299072266, 17.98849868774414, 59.11434555053711, 36.168556213378906, 174.82815551757812, 52.63295364379883, 97.73709869384766, 23.79950523376465, 53.301513671875, 26.607606887817383, 19.867637634277344, 34.401702880859375, 29.624549865722656, 57.3477783203125, 45.86960983276367, 18.159133911132812, 16.245838165283203, 14.335187911987305, 13.379990577697754, 13.37995719909668, 12.423786163330078, 12.426961898803711, 9.557437896728516, 11.470288276672363, 13.379118919372559, 8.600719451904297, 10.514150619506836, 7.646664142608643, 77.32823181152344, 23.89558982849121, 9.572035789489746, 12.456698417663574, 8.613306999206543, 10.530498504638672, 14.28315258026123, 50.606075286865234, 7.667906761169434, 7.667932510375977, 64.24403381347656, 10.549379348754883, 18.22992515563965, 33.5670280456543, 19.20049476623535, 38.16423797607422, 48.862667083740234, 53.301513671875, 75.90784454345703, 112.43057250976562, 61.37021255493164, 24.897743225097656, 31.56687355041504, 23.987220764160156, 40.650150299072266, 174.82815551757812, 115.00215911865234, 97.73709869384766, 27.96778678894043, 23.140117645263672, 22.180702209472656, 16.392070770263672, 13.497581481933594, 23.144672393798828, 17.353713989257812, 14.46146297454834, 11.568737030029297, 10.602855682373047, 12.53460693359375, 11.569265365600586, 11.569180488586426, 10.60360336303711, 31.81473159790039, 8.674089431762695, 9.638065338134766, 7.710049152374268, 9.639385223388672, 12.53598403930664, 12.534812927246094, 7.709924221038818, 9.639142990112305, 7.709946632385254, 32.74492263793945, 7.71066951751709, 9.640379905700684, 11.548325538635254, 15.434447288513184, 38.510154724121094, 17.371912002563477, 37.67576599121094, 16.373414993286133, 24.14603042602539, 112.43057250976562, 21.069684982299805, 23.088136672973633, 61.37021255493164, 30.867897033691406, 23.987220764160156], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2477999925613403, 1.2373000383377075, 1.2218999862670898, 1.2139999866485596, 1.2136000394821167, 1.2136000394821167, 1.2134000062942505, 1.211300015449524, 1.2094999551773071, 1.201200008392334, 1.1969000101089478, 1.1962000131607056, 1.1952999830245972, 1.1949000358581543, 1.1944999694824219, 1.1872999668121338, 1.1854000091552734, 1.1833000183105469, 1.1830999851226807, 1.1790000200271606, 1.1777000427246094, 1.176300048828125, 1.174299955368042, 1.1741000413894653, 1.1663000583648682, 1.163599967956543, 1.1632000207901, 1.1607999801635742, 1.1406999826431274, 1.1305999755859375, 1.1272000074386597, 1.0527000427246094, 1.069000005722046, 1.0621999502182007, 1.0914000272750854, 0.7874000072479248, 0.569100022315979, 0.670199990272522, 0.2531000077724457, 0.2321999967098236, 0.5202999711036682, 0.852400004863739, -0.23909999430179596, 0.08460000157356262, -0.9013000130653381, 1.259600043296814, 1.2581000328063965, 1.2581000328063965, 1.2556999921798706, 1.253100037574768, 1.2517999410629272, 1.2509000301361084, 1.250599980354309, 1.2391999959945679, 1.2375999689102173, 1.2232999801635742, 1.222599983215332, 1.2201000452041626, 1.211300015449524, 1.2106000185012817, 1.208799958229065, 1.2062000036239624, 1.2050000429153442, 1.194599986076355, 1.1902999877929688, 1.1836999654769897, 1.177899956703186, 1.17739999294281, 1.1686999797821045, 1.1608999967575073, 1.13919997215271, 1.0976999998092651, 1.0788999795913696, 1.0677000284194946, 1.0319000482559204, 0.9869999885559082, 0.9692999720573425, 0.8044000267982483, 0.9735000133514404, 0.5047000050544739, 0.6565999984741211, -0.007799999788403511, 0.4228000044822693, 0.13330000638961792, 0.7328000068664551, 0.09189999848604202, 0.558899998664856, 0.7350999712944031, 1.3423999547958374, 1.3352999687194824, 1.3215999603271484, 1.3187999725341797, 1.3177000284194946, 1.3138999938964844, 1.312000036239624, 1.3050999641418457, 1.304900050163269, 1.3004000186920166, 1.2874000072479248, 1.283400058746338, 1.2813999652862549, 1.2812000513076782, 1.267699956893921, 1.260200023651123, 1.259600043296814, 1.2408000230789185, 1.2164000272750854, 1.1766999959945679, 1.1125999689102173, 1.107300043106079, 1.0671000480651855, 1.0649000406265259, 1.0513999462127686, 1.0496000051498413, 1.049399971961975, 1.0424000024795532, 1.0335999727249146, 1.0311000347137451, 1.0169999599456787, 0.9776999950408936, 0.8177000284194946, 0.7745000123977661, 0.7441999912261963, 0.5846999883651733, 0.4171999990940094, 0.567799985408783, 0.8220999836921692, 0.6658999919891357, 0.7462000250816345, 0.3149999976158142, -0.9017999768257141, -0.5884000062942505, -0.49880000948905945, 1.6527999639511108, 1.6404000520706177, 1.6304999589920044, 1.6225999593734741, 1.621999979019165, 1.6200000047683716, 1.61899995803833, 1.6160000562667847, 1.6151000261306763, 1.604200005531311, 1.6038999557495117, 1.6035000085830688, 1.6035000085830688, 1.6019999980926514, 1.601199984550476, 1.5871000289916992, 1.5825999975204468, 1.5813000202178955, 1.5812000036239624, 1.5806000232696533, 1.579800009727478, 1.5789999961853027, 1.5774999856948853, 1.5664000511169434, 1.562600016593933, 1.5592999458312988, 1.5498000383377075, 1.542799949645996, 1.5317000150680542, 1.5125000476837158, 1.478700041770935, 1.3858000040054321, 1.4629000425338745, 1.36080002784729, 0.9118000268936157, 1.3428000211715698, 1.2992000579833984, 0.9215999841690063, 0.7613000273704529, 0.8561000227928162], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.535900115966797, -4.165500164031982, -3.6998000144958496, -4.594799995422363, -4.595300197601318, -4.595300197601318, -4.401400089263916, -4.192399978637695, -4.753499984741211, -4.608099937438965, -4.948699951171875, -4.949399948120117, -4.855000019073486, -4.855400085449219, -4.951099872589111, -3.572499990463257, -5.065700054168701, -4.269400119781494, -5.0680999755859375, -4.63100004196167, -3.53410005569458, -5.074999809265137, -5.194799900054932, -5.195099830627441, -5.203000068664551, -4.512400150299072, -2.9820001125335693, -3.7051000595092773, -5.006700038909912, -3.1607000827789307, -4.6153998374938965, -3.637200117111206, -3.914299964904785, -3.953900098800659, -4.415999889373779, -2.466599941253662, -3.266400098800659, -3.7841999530792236, -3.835200071334839, -4.106100082397461, -4.467800140380859, -4.656899929046631, -4.246099948883057, -4.444200038909912, -4.596799850463867, -3.392199993133545, -3.4381000995635986, -3.4611001014709473, -3.486999988555908, -3.7307000160217285, -3.7021000385284424, -3.7953999042510986, -3.7957000732421875, -2.6661999225616455, -4.246600151062012, -4.5482001304626465, -3.428499937057495, -4.620299816131592, -4.7829999923706055, -4.703700065612793, -4.7855000495910645, -4.708099842071533, -4.876200199127197, -4.88640022277832, -4.985899925231934, -4.992300033569336, -4.998000144958496, -5.103799819946289, -4.9120001792907715, -5.237800121307373, -5.141499996185303, -5.0767998695373535, -5.094699859619141, -2.60509991645813, -4.611599922180176, -3.01990008354187, -4.171599864959717, -3.908400058746338, -4.554500102996826, -3.8336000442504883, -4.173099994659424, -3.2618000507354736, -4.031700134277344, -3.702199935913086, -4.515399932861328, -4.349899768829346, -4.577700138092041, -4.693600177764893, -3.5373001098632812, -3.6939001083374023, -3.047100067138672, -3.273200035095215, -4.200900077819824, -4.315999984741211, -4.4430999755859375, -4.519000053405762, -4.519199848175049, -4.597799777984619, -4.610599994659424, -4.877099990844727, -4.696700096130371, -4.543000221252441, -4.998199939727783, -4.804900169372559, -5.124000072479248, -2.8289999961853027, -4.0278000831604, -4.9822001457214355, -4.7829999923706055, -5.157199859619141, -4.996500015258789, -4.69379997253418, -3.4423000812530518, -5.331200122833252, -5.331399917602539, -3.2126998901367188, -5.02810001373291, -4.483699798583984, -3.8873000144958496, -4.485199928283691, -3.958199977874756, -3.754300117492676, -3.697700023651123, -3.5035998821258545, -3.2783000469207764, -3.733099937438965, -4.380899906158447, -4.299799919128418, -4.494100093841553, -4.397799968719482, -4.155799865722656, -4.261300086975098, -4.3343000411987305, -3.4339001178741455, -3.6359000205993652, -3.6881000995635986, -3.998500108718872, -4.193299770355225, -3.656100034713745, -3.944999933242798, -4.13040018081665, -4.354400157928467, -4.452499866485596, -4.2855000495910645, -4.365900039672852, -4.366000175476074, -4.454599857330322, -3.3566999435424805, -4.670400142669678, -4.569499969482422, -4.794000148773193, -4.570799827575684, -4.308599948883057, -4.309500217437744, -4.796299934387207, -4.574399948120117, -4.808899879455566, -3.366499900817871, -4.815899848937988, -4.602099895477295, -4.428500175476074, -4.149499893188477, -3.2544000148773193, -4.084199905395508, -3.4030001163482666, -4.159299850463867, -3.8729000091552734, -2.7836999893188477, -4.027200222015381, -3.979300022125244, -3.379300117492676, -4.226799964904785, -4.384200096130371]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 3, 3, 1, 1, 2, 3, 4, 1, 2, 4, 2, 1, 1, 3, 4, 1, 1, 2, 1, 2, 1, 2, 3, 3, 1, 4, 3, 2, 3, 1, 3, 4, 1, 2, 3, 4, 2, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 2, 3, 4, 2, 3, 1, 4, 1, 1, 2, 3, 1, 3, 1, 4, 4, 4, 4, 3, 3, 2, 1, 2, 1, 4, 4, 1, 4, 3, 2, 2, 2, 3, 1, 3, 1, 2, 3, 4, 2, 4, 1, 1, 3, 1, 3, 1, 2, 3, 4, 2, 4, 1, 2, 4, 4, 1, 3, 4, 4, 2, 4, 4, 4, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 3, 1, 2, 3, 4, 2, 3, 1, 4, 4, 2, 1, 2, 3, 1, 2, 1, 2, 3, 4, 3, 1, 4, 1, 2, 3, 2, 3, 4, 3, 2, 1, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 1, 3, 2, 3, 4, 1, 2, 4, 1, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 4, 2, 1, 3, 2, 1, 2, 2, 4, 2, 1, 3, 2, 1, 1, 2, 3, 4, 1, 3, 1, 3, 4, 1, 2, 3, 2, 4, 1, 4, 1, 2, 3, 4, 4, 2, 3, 4, 2, 3, 1, 1, 3, 4, 1, 2, 3, 4, 1, 2, 4, 4, 1, 2, 3, 4, 4, 2, 2, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 2, 3, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 3, 1, 3, 1, 2, 3, 4], \"Freq\": [0.01629455015063286, 0.06517820060253143, 0.45624738931655884, 0.4725419580936432, 0.8559892773628235, 0.9416749477386475, 0.9277793169021606, 0.017437467351555824, 0.017437467351555824, 0.9590606689453125, 0.017437467351555824, 0.8060268759727478, 0.03224107623100281, 0.12896430492401123, 0.9576563239097595, 0.9809722304344177, 0.24848805367946625, 0.04141467437148094, 0.7454641461372375, 0.956929087638855, 0.9398095011711121, 0.030316434800624847, 0.9093319177627563, 0.07372961193323135, 0.9024608135223389, 0.848842442035675, 0.10610530525445938, 0.9766178131103516, 0.07977781444787979, 0.8775559663772583, 0.9154318571090698, 0.9614090323448181, 0.9883231520652771, 0.14895568788051605, 0.7149873375892639, 0.11916455626487732, 0.22118660807609558, 0.5253182053565979, 0.027648326009511948, 0.19353827834129333, 0.966346025466919, 0.9562956094741821, 0.8126959800720215, 0.11609942466020584, 0.16055618226528168, 0.8027809262275696, 0.9508384466171265, 0.9700216054916382, 0.9444320797920227, 0.05762455239892006, 0.921992838382721, 0.9218509197235107, 0.5419552326202393, 0.4585775136947632, 0.9747025966644287, 0.9658891558647156, 0.043206486850976944, 0.9505427479743958, 0.9573144912719727, 0.5509856343269348, 0.4179890751838684, 0.018999503925442696, 0.2608264982700348, 0.7824795246124268, 0.1295802742242813, 0.8422718048095703, 0.9150765538215637, 0.9653964042663574, 0.9431421160697937, 0.9789178371429443, 0.9716001152992249, 0.9885284304618835, 0.8843110799789429, 0.07369258999824524, 0.23888035118579865, 0.7431833148002625, 0.933692991733551, 0.10373035073280334, 0.8298428058624268, 0.9233133792877197, 0.9665571451187134, 0.9720680713653564, 0.6039973497390747, 0.4026648700237274, 0.2742742896080017, 0.7131131887435913, 0.05193435400724411, 0.07790152728557587, 0.025967177003622055, 0.8569168448448181, 0.9564008712768555, 0.9222869873046875, 0.9165039658546448, 0.7995803952217102, 0.1665792465209961, 0.3124919533729553, 0.677065908908844, 0.15839388966560364, 0.1900726705789566, 0.5068604350090027, 0.15839388966560364, 0.8480703234672546, 0.10600879043340683, 0.11324331164360046, 0.717207670211792, 0.15099108219146729, 0.9631354808807373, 0.06107461452484131, 0.12214922904968262, 0.793969988822937, 0.9337973594665527, 0.08659263700246811, 0.8659263849258423, 0.9336695075035095, 0.9079180955886841, 0.9166650176048279, 0.8955888152122498, 0.06889145076274872, 0.8168089389801025, 0.1633617877960205, 0.9446738958358765, 0.37815913558006287, 0.588247537612915, 0.08369745314121246, 0.04184872657060623, 0.8788232803344727, 0.031431980431079865, 0.031431980431079865, 0.031431980431079865, 0.9115273952484131, 0.967705488204956, 0.9589994549751282, 0.9371495842933655, 0.9078329801559448, 0.9680901765823364, 0.9565613865852356, 0.7934280633926392, 0.07212982326745987, 0.12021637707948685, 0.8260893225669861, 0.10326116532087326, 0.49111342430114746, 0.317177414894104, 0.15347294509410858, 0.030694589018821716, 0.9301547408103943, 0.17269256711006165, 0.8058986067771912, 0.9770857691764832, 0.21003766357898712, 0.7701380848884583, 0.3001790940761566, 0.5440745949745178, 0.1500895470380783, 0.9716024994850159, 0.992029070854187, 0.9164414405822754, 0.9361680150032043, 0.932680070400238, 0.04908842593431473, 0.8715252876281738, 0.08069679141044617, 0.0484180711209774, 0.8887986540794373, 0.05734185129404068, 0.02867092564702034, 0.21861043572425842, 0.7529914975166321, 0.024290047585964203, 0.3552437126636505, 0.45674192905426025, 0.16916367411613464, 0.016916368156671524, 0.9282087087631226, 0.05156714841723442, 0.02578357420861721, 0.9569288492202759, 0.9483027458190918, 0.04625866934657097, 0.26082736253738403, 0.7824821472167969, 0.6150038838386536, 0.34440216422080994, 0.024600155651569366, 0.03053908608853817, 0.06107817217707634, 0.8856334686279297, 0.07977036386728287, 0.8774740099906921, 0.8924737572669983, 0.04183470830321312, 0.05577960982918739, 0.11562691628932953, 0.03557751327753067, 0.3913526237010956, 0.4625076651573181, 0.17122212052345276, 0.01556564774364233, 0.7160198092460632, 0.07782823592424393, 0.9116639494895935, 0.9508020281791687, 0.929476797580719, 0.9279648065567017, 0.051553599536418915, 0.9747593998908997, 0.22236430644989014, 0.7226839661598206, 0.28476932644844055, 0.7119233012199402, 0.8997398614883423, 0.9023629426956177, 0.06445449590682983, 0.8998032808303833, 0.9371433854103088, 0.3069828450679779, 0.14325866103172302, 0.5525690913200378, 0.9467689394950867, 0.9023401141166687, 0.8851721286773682, 0.10447098314762115, 0.8357678651809692, 0.9079059958457947, 0.01097225770354271, 0.965558648109436, 0.03291677311062813, 0.9613913893699646, 0.9430756568908691, 0.9277268648147583, 0.95079505443573, 0.6120295524597168, 0.2745553255081177, 0.10295824706554413, 0.0057199024595320225, 0.9507298469543457, 0.080328568816185, 0.5622999668121338, 0.32131427526474, 0.8693968653678894, 0.09659965336322784, 0.9568888545036316, 0.04331228509545326, 0.25987371802330017, 0.6929965615272522, 0.9023029208183289, 0.021800925955176353, 0.9592407941818237, 0.021800925955176353, 0.4859417676925659, 0.12958446145057678, 0.38875341415405273, 0.9573495388031006, 0.3556944727897644, 0.07904321700334549, 0.46108540892601013, 0.10539095103740692, 0.9079207181930542, 0.990333616733551, 0.9705203771591187, 0.9277091026306152, 0.11856283992528915, 0.7311375141143799, 0.13832330703735352, 0.04347744584083557, 0.8086804747581482, 0.13912782073020935, 0.008695488795638084, 0.8259769678115845, 0.1179967075586319, 0.811115562915802, 0.1871805191040039, 0.7596981525421143, 0.18992453813552856, 0.10481016337871552, 0.2358228713274002, 0.5764558911323547, 0.07860761880874634, 0.18791618943214417, 0.4885820746421814, 0.30066588521003723, 0.012931887991726398, 0.07759132236242294, 0.8793683648109436, 0.025863775983452797, 0.8969200253486633, 0.1895846128463745, 0.758338451385498, 0.6546831727027893, 0.10911385715007782, 0.21822771430015564, 0.05455692857503891], \"Term\": [\"adaptation\", \"adaptation\", \"adaptation\", \"adaptation\", \"aerial\", \"african\", \"ancient\", \"animal\", \"animal\", \"animal\", \"animal\", \"architecture\", \"architecture\", \"architecture\", \"arctic\", \"area\", \"art\", \"art\", \"art\", \"astronomical\", \"atmosphere\", \"atmosphere\", \"atmospheric\", \"atmospheric\", \"backlighting\", \"beach\", \"beach\", \"beak\", \"beauty\", \"beauty\", \"big\", \"biology\", \"bird\", \"black\", \"black\", \"black\", \"blue\", \"blue\", \"blue\", \"blue\", \"boat\", \"body\", \"botany\", \"botany\", \"branch\", \"branch\", \"breed\", \"build\", \"calm\", \"canidae\", \"canidae\", \"cap\", \"carnivore\", \"carnivore\", \"cartilaginous\", \"cat\", \"child\", \"child\", \"city\", \"cloud\", \"cloud\", \"cloud\", \"coastal\", \"coastal\", \"crowd\", \"crowd\", \"design\", \"dog\", \"dress\", \"elephant\", \"elephants\", \"environment\", \"even\", \"even\", \"event\", \"event\", \"face\", \"fashion\", \"fashion\", \"felidae\", \"fin\", \"fish\", \"forest\", \"forest\", \"formation\", \"formation\", \"fun\", \"fun\", \"fun\", \"fun\", \"fur\", \"furniture\", \"game\", \"geological\", \"geological\", \"geology\", \"geology\", \"grass\", \"grass\", \"grass\", \"grass\", \"great\", \"great\", \"green\", \"green\", \"green\", \"group\", \"hair\", \"hair\", \"hair\", \"hand\", \"happy\", \"happy\", \"head\", \"headgear\", \"heat\", \"highland\", \"highland\", \"hill\", \"hill\", \"history\", \"horizon\", \"horizon\", \"horse\", \"horse\", \"horse\", \"human\", \"human\", \"human\", \"human\", \"ice\", \"indian\", \"infrastructure\", \"interior\", \"lady\", \"lake\", \"landforms\", \"landforms\", \"landforms\", \"landmark\", \"landmark\", \"landscape\", \"landscape\", \"landscape\", \"landscape\", \"leaf\", \"leisure\", \"leisure\", \"light\", \"lion\", \"lion\", \"mammal\", \"mammal\", \"mammal\", \"mammoths\", \"marine\", \"mist\", \"monochrome\", \"morning\", \"morning\", \"mountain\", \"mountain\", \"mountain\", \"mountainous\", \"mountainous\", \"mountainous\", \"natural\", \"natural\", \"natural\", \"nature\", \"nature\", \"nature\", \"nature\", \"night\", \"night\", \"night\", \"object\", \"ocean\", \"ocean\", \"oceanic\", \"oceanic\", \"organism\", \"organism\", \"organism\", \"people\", \"people\", \"people\", \"performance\", \"performance\", \"phenomenon\", \"phenomenon\", \"phenomenon\", \"photography\", \"photography\", \"photography\", \"photography\", \"plant\", \"plant\", \"plant\", \"plant\", \"polar\", \"portrait\", \"primate\", \"range\", \"range\", \"reef\", \"reflection\", \"reflection\", \"reptile\", \"reptile\", \"resources\", \"ridge\", \"ridge\", \"river\", \"road\", \"rock\", \"rock\", \"rock\", \"room\", \"rural\", \"safari\", \"savanna\", \"savanna\", \"scale\", \"sea\", \"sea\", \"sea\", \"shark\", \"sit\", \"site\", \"skin\", \"sky\", \"sky\", \"sky\", \"sky\", \"smile\", \"snout\", \"snout\", \"snout\", \"snow\", \"snow\", \"space\", \"sport\", \"sport\", \"sport\", \"star\", \"terrestrial\", \"terrestrial\", \"terrestrial\", \"tourism\", \"tourism\", \"tourism\", \"tradition\", \"tree\", \"tree\", \"tree\", \"tree\", \"tribe\", \"turtle\", \"underwater\", \"urban\", \"vertebrate\", \"vertebrate\", \"vertebrate\", \"water\", \"water\", \"water\", \"water\", \"watercourse\", \"watercourse\", \"wave\", \"wave\", \"whisker\", \"whisker\", \"white\", \"white\", \"white\", \"white\", \"wilderness\", \"wilderness\", \"wilderness\", \"wildlife\", \"wildlife\", \"wildlife\", \"wildlife\", \"woody\", \"work\", \"work\", \"yellow\", \"yellow\", \"yellow\", \"yellow\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1614818270360183922917823935\", ldavis_el1614818270360183922917823935_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1614818270360183922917823935\", ldavis_el1614818270360183922917823935_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1614818270360183922917823935\", ldavis_el1614818270360183922917823935_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3     -0.104166 -0.223752       1        1  27.970814\n",
       "0     -0.206627  0.114365       2        1  27.869904\n",
       "1      0.028457  0.120374       3        1  25.516808\n",
       "2      0.282336 -0.010987       4        1  18.642466, topic_info=    Category        Freq         Term       Total  loglift  logprob\n",
       "41   Default   91.000000          sea   91.000000  30.0000  30.0000\n",
       "19   Default  115.000000        water  115.000000  29.0000  29.0000\n",
       "37   Default   77.000000     wildlife   77.000000  28.0000  28.0000\n",
       "30   Default   57.000000       animal   57.000000  27.0000  27.0000\n",
       "4    Default  174.000000          sky  174.000000  26.0000  26.0000\n",
       "24   Default   71.000000   phenomenon   71.000000  25.0000  25.0000\n",
       "13   Default  112.000000  photography  112.000000  24.0000  24.0000\n",
       "33   Default   45.000000  terrestrial   45.000000  23.0000  23.0000\n",
       "89   Default   43.000000         fish   43.000000  22.0000  22.0000\n",
       "51   Default   82.000000      natural   82.000000  21.0000  21.0000\n",
       "90   Default   41.000000       marine   41.000000  20.0000  20.0000\n",
       "50   Default   61.000000     mountain   61.000000  19.0000  19.0000\n",
       "170  Default   40.000000       turtle   40.000000  18.0000  18.0000\n",
       "107  Default   38.000000          fun   38.000000  17.0000  17.0000\n",
       "47   Default   39.000000  environment   39.000000  16.0000  16.0000\n",
       "8    Default   31.000000        human   31.000000  15.0000  15.0000\n",
       "40   Default   43.000000        ocean   43.000000  14.0000  14.0000\n",
       "158  Default   27.000000          dog   27.000000  13.0000  13.0000\n",
       "11   Default   32.000000       people   32.000000  12.0000  12.0000\n",
       "139  Default   34.000000         bird   34.000000  11.0000  11.0000\n",
       "29   Default   37.000000        light   37.000000  10.0000  10.0000\n",
       "84   Default   37.000000        event   37.000000   9.0000   9.0000\n",
       "81   Default   61.000000   adaptation   61.000000   8.0000   8.0000\n",
       "22   Default   40.000000  atmospheric   40.000000   7.0000   7.0000\n",
       "174  Default   31.000000   underwater   31.000000   6.0000   6.0000\n",
       "181  Default   29.000000     elephant   29.000000   5.0000   5.0000\n",
       "3    Default   64.000000        plant   64.000000   4.0000   4.0000\n",
       "72   Default   23.000000        smile   23.000000   3.0000   3.0000\n",
       "48   Default   31.000000          ice   31.000000   2.0000   2.0000\n",
       "2    Default   38.000000        night   38.000000   1.0000   1.0000\n",
       "..       ...         ...          ...         ...      ...      ...\n",
       "140   Topic4   11.618889    tradition   12.534607   1.6039  -4.2855\n",
       "59    Topic4   10.720500         skin   11.569265   1.6035  -4.3659\n",
       "130   Topic4   10.719924     portrait   11.569180   1.6035  -4.3660\n",
       "108   Topic4    9.810752          sit   10.603603   1.6020  -4.4546\n",
       "8     Topic4   29.410965        human   31.814732   1.6012  -3.3567\n",
       "94    Topic4    7.906482    furniture    8.674089   1.5871  -4.6704\n",
       "128   Topic4    8.745991         hand    9.638065   1.5826  -4.5695\n",
       "175   Topic4    6.987403        scale    7.710049   1.5813  -4.7940\n",
       "58    Topic4    8.734723         head    9.639385   1.5812  -4.5708\n",
       "129   Topic4   11.352663  performance   12.535984   1.5806  -4.3086\n",
       "26    Topic4   11.342611       beauty   12.534813   1.5798  -4.3095\n",
       "135   Topic4    6.971227        tribe    7.709924   1.5790  -4.7963\n",
       "56    Topic4    8.702846         face    9.639143   1.5775  -4.5744\n",
       "124   Topic4    6.883596     headgear    7.709947   1.5664  -4.8089\n",
       "11    Topic4   29.124338       people   32.744923   1.5626  -3.3665\n",
       "110   Topic4    6.835580     interior    7.710670   1.5593  -4.8159\n",
       "27    Topic4    8.465379      fashion    9.640380   1.5498  -4.6021\n",
       "137   Topic4   10.070031        happy   11.548326   1.5428  -4.4285\n",
       "69    Topic4   13.310863        crowd   15.434447   1.5317  -4.1495\n",
       "107   Topic4   32.579189          fun   38.510155   1.5125  -3.2544\n",
       "93    Topic4   14.208534      leisure   17.371912   1.4787  -4.0842\n",
       "84    Topic4   28.079777        event   37.675766   1.3858  -3.4030\n",
       "71    Topic4   13.181481         hair   16.373415   1.4629  -4.1593\n",
       "82    Topic4   17.553131          art   24.146030   1.3608  -3.8729\n",
       "13    Topic4   52.165352  photography  112.430573   0.9118  -2.7837\n",
       "169   Topic4   15.043327      reptile   21.069685   1.3428  -4.0272\n",
       "147   Topic4   15.780628        sport   23.088137   1.2992  -3.9793\n",
       "81    Topic4   28.754601   adaptation   61.370213   0.9216  -3.3793\n",
       "143   Topic4   12.320725      tourism   30.867897   0.7613  -4.2268\n",
       "73    Topic4   10.526040    carnivore   23.987221   0.8561  -4.3842\n",
       "\n",
       "[203 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "81        1  0.016295    adaptation\n",
       "81        2  0.065178    adaptation\n",
       "81        3  0.456247    adaptation\n",
       "81        4  0.472542    adaptation\n",
       "185       3  0.855989        aerial\n",
       "180       3  0.941675       african\n",
       "151       1  0.927779       ancient\n",
       "30        1  0.017437        animal\n",
       "30        2  0.017437        animal\n",
       "30        3  0.959061        animal\n",
       "30        4  0.017437        animal\n",
       "16        1  0.806027  architecture\n",
       "16        2  0.032241  architecture\n",
       "16        4  0.128964  architecture\n",
       "45        2  0.957656        arctic\n",
       "118       1  0.980972          area\n",
       "82        1  0.248488           art\n",
       "82        3  0.041415           art\n",
       "82        4  0.745464           art\n",
       "20        1  0.956929  astronomical\n",
       "21        1  0.939810    atmosphere\n",
       "21        2  0.030316    atmosphere\n",
       "22        1  0.909332   atmospheric\n",
       "22        2  0.073730   atmospheric\n",
       "53        1  0.902461  backlighting\n",
       "164       2  0.848842         beach\n",
       "164       3  0.106105         beach\n",
       "138       3  0.976618          beak\n",
       "26        1  0.079778        beauty\n",
       "26        4  0.877556        beauty\n",
       "...     ...       ...           ...\n",
       "35        3  0.731138    vertebrate\n",
       "35        4  0.138323    vertebrate\n",
       "19        1  0.043477         water\n",
       "19        2  0.808680         water\n",
       "19        3  0.139128         water\n",
       "19        4  0.008695         water\n",
       "188       2  0.825977   watercourse\n",
       "188       3  0.117997   watercourse\n",
       "42        2  0.811116          wave\n",
       "42        3  0.187181          wave\n",
       "36        3  0.759698       whisker\n",
       "36        4  0.189925       whisker\n",
       "15        1  0.104810         white\n",
       "15        2  0.235823         white\n",
       "15        3  0.576456         white\n",
       "15        4  0.078608         white\n",
       "141       1  0.187916    wilderness\n",
       "141       2  0.488582    wilderness\n",
       "141       3  0.300666    wilderness\n",
       "37        1  0.012932      wildlife\n",
       "37        2  0.077591      wildlife\n",
       "37        3  0.879368      wildlife\n",
       "37        4  0.025864      wildlife\n",
       "6         3  0.896920         woody\n",
       "190       1  0.189585          work\n",
       "190       3  0.758338          work\n",
       "55        1  0.654683        yellow\n",
       "55        2  0.109114        yellow\n",
       "55        3  0.218228        yellow\n",
       "55        4  0.054557        yellow\n",
       "\n",
       "[292 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 2, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task D. What advice would you give National Geographic if it wants to increase engagement on its Instagram page based on your findings in Tasks B and C?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the topic modeling findings, if National Geographic wants to increase engagement, they should focus on posting pictures of animals, especially terrestrial animals. The posts which exhibit lower engagement on average are pictures of people, while the posts which exhibit higher engagement on average are posts of animals. \n",
    "\n",
    "\n",
    "The top ten key words associated with the topic which generated the highest engagement were wildlife, animal, plant, terrestrial, photography, vertebrate, tree, bird, elephant, and mammal. Perhaps there is so much content of people on Instagram that National Geographic differentiates itself through pictures of wildlife. This theory is further substantiated by the low engagement for posts that contain either people or more domestic content. The key words in the topic which generated the lowest engagement were photography, fun, human, people, adaptation, event, dog, smile, child, and room.\n",
    "\n",
    "\n",
    "Currently, engagement can be successfully predicted by the content of the captions, suggesting their importance. However, no additional information is gained by including both the photo labels and the captions. This seems to indicate that National Geographic is typically reiterating the content in the photo again in the caption. The company could try some A/B Testing with captions that include other insights related to the picture without reiterating the photos content to see if there is an impact on engagement. However, this should be considered a secondary priority, as the effects on engagement are uncertain. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
